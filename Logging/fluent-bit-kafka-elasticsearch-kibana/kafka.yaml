apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: zookeeper
  namespace: logging
  labels:
    app: zookeeper
    component: server
spec:
  selector:
    matchLabels:
      app: zookeeper
      component: server
  # 控制Pod集群处于运行状态的最低个数,保证主动销毁应用Pod时不知一次销毁过多Pod
  # 最大不可用的Pod个数
  maxUnavailable: 1
---
# zookeeper headless service
apiVersion: v1
kind: Service
metadata:
  name: zookeeper-headless
  namespace: logging
  labels:
    app: zookeeper
spec:
  clusterIP: None
  ports:
  - name: client
    port: 2181
    targetPort: 2181
    protocol: TCP
  - name: election
    port: 3888
    targetPort: 3888
    protocol: TCP
  - name: server
    port: 2888
    targetPort: 2888
    protocol: TCP
  selector:
    app: zookeeper
---
# zookeeper service
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: logging
  labels:
    app: zookeeper
spec:
  type: ClusterIP
  ports:
  - name: client
    port: 2181
    targetPort: client
  selector:
    app: zookeeper
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: logging
  labels:
    app: kafka
spec:
  clusterIP: None
  ports:
  - name: broker
    port: 9092
  selector:
    app: kafka
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: logging
  labels:
    app: kafka
spec:
  type: ClusterIP
  ports:
  - name: broker
    port: 9092
    targetPort: kafka
  selector:
    app: kafka
---
apiVersion: v1
kind: Pod
metadata:
  name: kafka-test-topic-create-consume-produce
  namespace: logging
  annotations:
    helm.sh/hook: test-success
spec:
  restartPolicy: Never
  containers:
  - name: kafka-test-consume
    image: confluentinc/cp-kafka:5.0.1
    command:
    - sh
    - -c
    - >
      # 创建topic
      kafka-topics --zookeeper zookeeper:2181 --topic helm-test-topic-create-consume-produce --create --partitions 1 --replication-factor 1 --if-not-exists && \
      # 创建message
      MESSAGE="`date -u`" && \
      # producer生成一段test message到topic
      echo "$MESSAGE" | kafka-console-producer --broker-list kafka:9092 --topic helm-test-topic-create-consume-produce && \
      # consumer从topic获取这段test message
      kafka-console-consumer --bootstrap-server kafka-headless:9092 --topic helm-test-topic-create-consume-produce --from-beginning --timeout-ms 2000 --max-messages 1 | grep "$MESSAGE"
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zookeeper
  namespace: logging
  labels:
    app: zookeeper
    component: server
spec:
  serviceName: zookeeper-headless
  replicas: 3
  selector:
    matchExpressions:
    - key: app
      operator: In
      values: ["zookeeper"]
    - key: component
      operator: In
      values: ["server"]
  updateStrategy:
    type: OnDelete
  template:
    metadata:
      labels:
        app: zookeeper
        component: server
        version: v1
    spec:
      tolerations:
      - key: node.kubernetes.io/unreachable
        operator: Exists
        effect: NoSchedule
      terminationGracePeriodSeconds: 1800
      securityContext:
        # 使得能够修改volume,这里也设置了用户身份;要与Dockerfile中定义的用户的UID一致
        fsGroup: 1000
        runAsUser: 1000
      containers:
      - name: zookeeper
        #image: gcr.io/google_samples/k8szk:v3
        image: solomonlinux/zookeeper:3.4.14
        imagePullPolicy: IfNotPresent
        #command:
        #- /bin/bash
        #- -xec
        #- zkGenConfig.sh && exec zkServer.sh start-foreground
        ports:
        - name: client
          containerPort: 2181
          protocol: TCP
        - name: election
          containerPort: 3888
          protocol: TCP
        - name: server
          containerPort: 2888
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - zkOk.sh
          initialDelaySeconds: 20
        livenessProbe:
          exec:
            command:
            - zkOk.sh
          initialDelaySeconds: 20
        env:
        - name: ZK_REPLICAS
          value: "3"
        - name: JMXAUTH
          value: "false"
        - name: JMXDISABLE
          value: "false"
        - name: JMXPORT
          value: "1099"
        - name: JMXSSL
          value: "false"
        - name: ZK_CLIENT_PORT
          value: "2181"
        - name: ZK_ELECTION_PORT
          value: "3888"
        - name: ZK_HEAP_SIZE
          value: "1G"
        - name: ZK_INIT_LIMIT
          value: "5"
        - name: ZK_LOG_LEVEL
          value: "INFO"
        - name: ZK_MAX_CLIENT_CNXNS
          value: "60"
        - name: ZK_MAX_SESSION_TIMEOUT
          value: "40000"
        - name: ZK_MIN_SESSION_TIMEOUT
          value: "4000"
        - name: ZK_PURGE_INTERVAL
          value: "0"
        - name: ZK_SERVER_PORT
          value: "2888"
        - name: ZK_SNAP_RETAIN_COUNT
          value: "3"
        - name: ZK_SYNC_LIMIT
          value: "10"
        - name: ZK_TICK_TIME
          value: "2000"
        resources:
          {}
        volumeMounts:
        - name: data
          mountPath: /var/lib/zookeeper
      volumes:
      - name: data
        emptyDir: {}
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: logging
  labels:
    app: kafka
spec:
  serviceName: kafka-headless
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: OnDelete
  replicas: 3
  selector:
    matchExpressions:
    - key: app
      operator: In
      values: ["kafka"]
  template:
    metadata:
      labels:
        app: kafka
        version: v1
    spec:
      tolerations:
      - key: node.kubernetes.io/unreachable
        operator: Exists
        effect: NoSchedule
      #- operator: Exists
      #  effect: NoSchedule
      #- operator: Exists
      #  effect: NoExecute
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:5.0.1
        imagePullPolicy: IfNotPresent
        readinessProbe:
          tcpSocket:
            port: kafka
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        livenessProbe:
          exec:
            command:
            - sh
            - -ec
            - /usr/bin/jps | /bin/grep -q SupportedKafka
          initialDelaySeconds: 30
          timeoutSeconds: 5
        ports:
        - name: kafka
          containerPort: 9092
        resources:
          {}
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: KAFKA_HEAP_OPTS
          value: -Xmx1G -Xms1G
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_LOG_DIRS
          value: "/opt/kafka/data/logs"
        - name: KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE
          value: "false"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_JMX_PORT
          value: "5555"
        command:
        - sh
        - -exc
        - >
          unset KAFKA_PORT && \
          export KAFKA_BROKER_ID=${POD_NAME##*-} && \
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_NAME}.kafka-headless.${POD_NAMESPACE}:9092 && \
          exec /etc/confluent/docker/run
        volumeMounts:
        - name: datadir
          mountPath: /opt/kafka/data
      #volumes:
      #- {}
      terminationGracePeriodSeconds: 60
  volumeClaimTemplates:
  - metadata:
      name: datadir
      namespace: logging
    spec:
      storageClassName: ceph-rbd-storage
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 1Gi
